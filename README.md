# Controlling_Robo_Car_with_Hand_Gesture
This project showcases a hand gesture-controlled robot car that combines computer vision and embedded systems. Using Python, MediaPipe, and OpenCV, the system detects hand gestures in real-time through a webcam. Each gesture—such as an open palm, fist, or finger combination—is interpreted into a specific command like move forward, turn left, stop, and so on. These commands are sent via serial communication to an Arduino, which then drives a robot car using a motor driver (L298N) and DC motors. This allows intuitive, wireless-like control of the robot without using Bluetooth or other RF modules. The entire system is powered by a simple webcam and runs on a computer that sends instructions to the Arduino. This project is ideal for learners who want to explore real-time computer vision, Arduino-based robotics, and gesture recognition. All required hardware components (Arduino Uno, L298N, motors, chassis, and battery) and software dependencies (OpenCV, MediaPipe, PySerial) are documented, making it easy to replicate and expand. Future improvements may include training a custom gesture recognition model using deep learning, using Raspberry Pi for standalone functionality, and enabling wireless communication.

